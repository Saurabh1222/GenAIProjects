# ğŸ¤– GenAI PDF Question-Answering (RAG App)

This project is a simple **Retrieval-Augmented Generation (RAG)** pipeline that allows you to **ask questions from a PDF document**, and get smart answers using **MiniLM embeddings + Flan-T5 LLM** â€” all without needing a GPU.

---

## ğŸ§  How it Works

1. ğŸ“„ **Read a PDF**
2. âœ‚ï¸ **Split it into chunks**
3. ğŸ” **Create vector embeddings** using `all-MiniLM-L6-v2`
4. ğŸ§Š **Store in FAISS** (vector database)
5. â“ **Query with a question**
6. ğŸ’¬ **Get an answer** from a small LLM (`flan-t5-base`)

---

## ğŸ“ Project Structure

```bash
.
â”œâ”€â”€ GenAI_QA_Project.ipynb    # Main notebook (can export as .py)
â”œâ”€â”€ README.md                 # This file
â””â”€â”€ GenAI_QA_Project_Interview_Questions.pdf  # Your input file
```
---

## ğŸ“Œ Notes

- This version uses **Flan-T5** (*fast, light, free*) â€” ideal for basic Q&A tasks.
- You can later upgrade to more advanced models like **Mistral**,


